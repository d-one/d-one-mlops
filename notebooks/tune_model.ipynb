{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fea36ec6-81a2-4ee6-a9e1-f9eef269a922",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1> AMLD Workshop </h1>\n",
    "    <h2>The Full Machine Learning Lifecycle - How to Use Machine Learning in Production (MLOps)</h2>\n",
    "    <h3>March 27, 2022</h3>\n",
    "<hr>\n",
    "<h1>Model tuning - Improve your model performance</h1>\n",
    "<hr>\n",
    " </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa1c7cb-5aa2-41be-911c-0a646fbc3653",
   "metadata": {},
   "source": [
    "If you opened this notebook, your model probably needs improvements. Use this notebook to find a set-up that produces a better model. You might experiment with hyper-parameter tuning, or even try different algorithms.\n",
    "\n",
    "First, similar to the MLflow exercise, lets import the relevant libraries ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066ae8ac-2e71-42c1-bd06-475861dccd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# functions needed for data pre processing\n",
    "from cd4ml.data_processing.ingest_data import get_data\n",
    "from cd4ml.data_processing.split_train_test import get_train_test_split\n",
    "from cd4ml.data_processing.transform_data import get_transformed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c55d170-3dd8-468a-ad90-df68713a4d3b",
   "metadata": {},
   "source": [
    "... set the paths and variables ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ea2211-5e43-4ff8-be7f-82a6b53be2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_raw_data_dir = '/mnt/raw/winji/day2'\n",
    "_root_dir = os.environ.get('PROJECT_PATH')\n",
    "\n",
    "if _root_dir is None:\n",
    "    raise ValueError('PROJECT_PATH environment variable not set')\n",
    "\n",
    "_data_dir = os.path.join(_root_dir, 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857f96d2-4ae5-4644-8286-df629bc25d5a",
   "metadata": {},
   "source": [
    "... and prepare the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3e0d60-0cd8-4d97-9efb-d8f82abcadcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data\n",
    "n_days_validation_set = 20\n",
    "\n",
    "df_raw = get_data(_raw_data_dir)\n",
    "df_all_train_data, _ = get_train_test_split(df_raw, n_days_test=20)\n",
    "df_train, df_val = get_train_test_split(df_all_train_data, n_days_validation_set)\n",
    "x_train, y_train = get_transformed_data(df_train)\n",
    "x_val, y_val = get_transformed_data(df_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b066ea5-b995-4a35-a983-77c875f075a5",
   "metadata": {},
   "source": [
    "Now see how well the model performs on your training and validation data and try to adjust and improve it. Make sure you set the ```_experiment_name``` and use the MLflow UI to inspect your model runs. Log all the relevant metrics and parameters as you have seen in the MLflow exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2aec73-5845-4074-bf02-2946a111604f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE YOUR MODEL HERE:\n",
    "def get_model():\n",
    "    C = 1.0\n",
    "    iterations = 50\n",
    "    model = LogisticRegression(C=C, max_iter=iterations)\n",
    "    return model\n",
    "\n",
    "# SET THE MLFLOW EXPERIMENT HERE:\n",
    "# _experiment_name = \"#####_tracking_exercise\"\n",
    "\n",
    "if not _experiment_name:\n",
    "    raise ValueError('_experiment_name not set')\n",
    "\n",
    "mlflow.set_experiment(_experiment_name)\n",
    "mlflow.autolog()\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    print(f\"\\nActive run_id: {run.info.run_id}\")\n",
    "\n",
    "    # fit your classifier\n",
    "    clf = get_model()\n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "    y_val_pred = clf.predict(x_val)\n",
    "\n",
    "    # CALCULATE YOUR METRICS HERE:\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    val_f1 = f1_score(y_val, y_val_pred, average='macro')\n",
    "    print('Accuracy validation set:', val_accuracy)\n",
    "    print('F1-score validation set:', val_f1)\n",
    "\n",
    "    # LOG COMMANDS HERE:\n",
    "    mlflow.log_metric('val_acc', val_accuracy)\n",
    "    mlflow.log_metric('val_f1', val_f1)\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a19976e-da99-4730-a5cf-7de16b071ad2",
   "metadata": {},
   "source": [
    "Once you are satisfied with the model performance, adjust the ```get_model()``` function in the code (located in ```cd4ml-workshop/cd4ml/model_training/train_model.py```) accordingly and (re-)run the CI-pipeline with Apache Airflow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop",
   "language": "python",
   "name": "workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
